{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/baraki-weldat/Cypher-Generation/blob/main/Final_ChatGPT_In_Context_Learning_with_Prompt_Engineering_GPT_3_5_Turbo_.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Installing Necessary Tools and Packages\n"
      ],
      "metadata": {
        "id": "9bLVveTJd5a5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "%pip install langchain\n",
        "%pip install openai langchain-openai\n",
        "%pip install langchainhub\n",
        "%pip install neo4j\n",
        "%pip install langchain-community langchain-core\n",
        "%pip install openai==0.28\n",
        "%pip install nltk rouge-score"
      ],
      "metadata": {
        "collapsed": true,
        "id": "r4CtZq9dd2dl"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Import Implementation Packages\n"
      ],
      "metadata": {
        "id": "MYN8xiEPgxGt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "import string\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from langchain_openai import ChatOpenAI\n",
        "from langchain_community.graphs  import Neo4jGraph\n",
        "from langchain.chains import GraphCypherQAChain\n",
        "from langchain.prompts import PromptTemplate\n",
        "from langchain.chains.graph_qa.cypher_utils import CypherQueryCorrector, Schema\n",
        "import openai\n",
        "from neo4j import GraphDatabase\n",
        "import nltk\n",
        "from nltk.translate.bleu_score import sentence_bleu,SmoothingFunction\n",
        "from rouge_score import rouge_scorer"
      ],
      "metadata": {
        "id": "Z_gLutI3g2ip"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data Preparation and Cleaning"
      ],
      "metadata": {
        "id": "HGZxeN3Ph2_m"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "drive.mount(\"/content/drive\", force_remount=True)\n",
        "# Import the datasets\n",
        "EvalCompanies = pd.read_excel(\"/content/drive/MyDrive/R and D from ABE/Raw Datasets/Companies Dataset.xlsx\")\n",
        "EvalMovies = pd.read_excel(\"/content/drive/MyDrive/R and D from ABE/Raw Datasets/Movies Dataset.xlsx\")\n",
        "EvalNetwork = pd.read_excel(\"/content/drive/MyDrive/R and D from ABE/Raw Datasets/Network Datasets.xlsx\")"
      ],
      "metadata": {
        "id": "9JSjA7lh8Ekz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1b13ad6d-1886-42b1-dd0b-da7502a48e44"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Drop unnecessary Columns\n",
        "print(EvalCompanies.columns, EvalNetwork.columns, EvalMovies.columns)\n",
        "EvalCompanies = EvalCompanies[['Natural Language Question', 'Cypher Query']]\n",
        "EvalMovies = EvalMovies[['question', 'cypher']]\n",
        "EvalNetwork = EvalNetwork[['Natural Language Question', 'Cypher Query']]\n",
        "print(EvalCompanies.columns, EvalNetwork.columns, EvalMovies.columns)\n",
        "# Rename Column names of the movies\n",
        "EvalMovies= EvalMovies.rename(columns={'question': 'Natural Language Question', 'cypher': 'Cypher Query'})\n",
        "print(\"The number of Evaluation datasets\")\n",
        "EvalCompanies.count(),EvalMovies.count(), EvalNetwork.count()\n",
        "print(\"Total Evaluation datasets are:\", len(EvalCompanies),len(EvalMovies),len(EvalNetwork))\n",
        "\n",
        "# Drop entries with null values\n",
        "EvalNetwork = EvalNetwork.dropna()\n",
        "EvalMovies = EvalMovies.dropna()\n",
        "EvalCompanies = EvalCompanies.dropna()\n",
        "EvalNetwork.isnull().sum(), EvalMovies.isnull().sum(),EvalCompanies.isnull().sum()\n",
        "\n",
        "# Rename Columns for Conformity\n",
        "EvalMovies.columns =  [\"Natural_Language_Question\", \"Cypher_Query\"]\n",
        "EvalCompanies.columns= [\"Natural_Language_Question\", \"Cypher_Query\"]\n",
        "EvalNetwork.columns = [\"Natural_Language_Question\", \"Cypher_Query\"]\n",
        "\n",
        "# Data Preprocessing\n",
        "def Preprocess(text):\n",
        "    PreProcessedText = text.lower().translate(str.maketrans('', '', string.punctuation))    # Convert to lowercase\n",
        "    return PreProcessedText\n",
        "\n",
        "# Preprocess the evaluation datasets\n",
        "EvalMovies[\"Natural_Language_Question\"]  = EvalMovies[\"Natural_Language_Question\"].apply(Preprocess)\n",
        "EvalCompanies[\"Natural_Language_Question\"]  = EvalCompanies[\"Natural_Language_Question\"].apply(Preprocess)\n",
        "EvalNetwork[\"Natural_Language_Question\"]  = EvalNetwork[\"Natural_Language_Question\"].apply(Preprocess)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kyK-NmdRG2Xz",
        "outputId": "a8a20b28-3bc4-4d98-a76d-0df14bc9d155"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Index(['Natural Language Question', 'Cypher Query', 'Unnamed: 2'], dtype='object') Index(['Natural Language Question', 'Cypher Query'], dtype='object') Index(['question', 'cypher', 'validated_cypher', 'vote', 'has_answer',\n",
            "       'database', 'database.1', 'Status'],\n",
            "      dtype='object')\n",
            "Index(['Natural Language Question', 'Cypher Query'], dtype='object') Index(['Natural Language Question', 'Cypher Query'], dtype='object') Index(['question', 'cypher'], dtype='object')\n",
            "The number of Evaluation datasets\n",
            "Total Evaluation datasets are: 139 265 69\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# On Movies Dataset"
      ],
      "metadata": {
        "id": "QMjxgfqtLeWN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# @title\n",
        "# Set up the OpenAI API key\n",
        "openai.api_key = 'sk-proj-'\n",
        "\n",
        "\n",
        "MOVIE_CYPHER_GENERATION_TEMPLATE = \"\"\"\n",
        "[INST]\n",
        "You are an expert Neo4j Developer translating user questions into Cypher to answer questions about movies and provide recommendations.\n",
        "Convert the user's question based on the schema.\n",
        "\n",
        "Instructions:\n",
        "    1. Use only the provided relationship types and properties in the schema.\n",
        "    2. Do not use any other relationship types or properties that are not provided.\n",
        "    3. If no data is returned, Generate the Cypher.\n",
        "    4. Only respond to questions that require you to construct a Cypher statement.\n",
        "    5. Do not respond to any questions that might ask anything else than for you to construct a Cypher statement.\n",
        "    6. Do not include any explanations or apologies in your responses.\n",
        "    7. Do not include any text except the generated Cypher statement.\n",
        "    8. Generate the Cypher, even if there are exceptions and errors in the query.\n",
        "\n",
        "Schema: {schema}\n",
        "Question: {question}\n",
        "List all movies and persons acted in the movies.\n",
        "[/INST]\n",
        "Query:\n",
        "QUERY: MATCH (p:Person)-[:ACTED_IN]->(m:Movie)\n",
        "RETURN m.title, p.name\n",
        "\"\"\"\n",
        "\n",
        "def generate_cypher(prompt, schema):\n",
        "    formatted_prompt = MOVIE_CYPHER_GENERATION_TEMPLATE.format(schema=schema, question=prompt)\n",
        "    response = openai.ChatCompletion.create(\n",
        "        model=\"gpt-3.5-turbo-0125\",\n",
        "        messages=[\n",
        "            {\"role\": \"user\", \"content\": formatted_prompt}\n",
        "        ]\n",
        "    )\n",
        "\n",
        "    # Extract the Cypher query from the response\n",
        "    cypher_query = response['choices'][0]['message']['content'].strip()\n",
        "    return cypher_query\n",
        "\n",
        "def run_cypher_query(query):\n",
        "    # Replace with your Neo4j connection details\n",
        "    uri = \"neo4j+s://demo.neo4jlabs.com\"\n",
        "    user = \"movies\"\n",
        "    password = \"movies\"\n",
        "\n",
        "    driver = GraphDatabase.driver(uri, auth=(user, password))\n",
        "\n",
        "    with driver.session() as session:\n",
        "        result = session.run(query)\n",
        "        return result.values()\n",
        "\n",
        "def evaluate_generated_query(description, expected_query, schema):\n",
        "    generated_query = generate_cypher(description, schema)\n",
        "    print(f\"Natural_Language_Question: {description}\")\n",
        "    print(f\"Generated Query: {generated_query}\")\n",
        "    print(f\"Expected Query: {expected_query}\")\n",
        "\n",
        "    # Tokenize the queries\n",
        "    generated_tokens = generated_query.split()\n",
        "    expected_tokens = expected_query.split()\n",
        "\n",
        "    Smooth = SmoothingFunction()\n",
        "    # BLEU score\n",
        "    bleu_score = sentence_bleu([expected_tokens], generated_tokens, smoothing_function=Smooth.method2 )\n",
        "\n",
        "    # ROUGE score\n",
        "    scorer = rouge_scorer.RougeScorer(['rouge1', 'rougeL'], use_stemmer=True)\n",
        "    rouge_scores = scorer.score(expected_query, generated_query)\n",
        "\n",
        "    return {\n",
        "        \"bleu\": bleu_score,\n",
        "        # \"meteor\": meteor,\n",
        "        \"rouge1\": rouge_scores['rouge1'].fmeasure,\n",
        "        \"rougeL\": rouge_scores['rougeL'].fmeasure }\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "\n",
        "\n",
        "    # Define the database schema\n",
        "    schema = \"\"\"\n",
        "    Node properties are the following:\n",
        "        Movie {title: STRING, votes: INTEGER, tagline: STRING, released: INTEGER}\n",
        "        Person {born: INTEGER, name: STRING}\n",
        "    Relationship properties are the following:\n",
        "        ACTED_IN {roles: LIST}\n",
        "        REVIEWED {summary: STRING, rating: INTEGER}\n",
        "    The relationships are the following:\n",
        "        (:Person)-[:ACTED_IN]->(:Movie)\n",
        "        (:Person)-[:DIRECTED]->(:Movie)\n",
        "        (:Person)-[:PRODUCED]->(:Movie)\n",
        "        (:Person)-[:WROTE]->(:Movie)\n",
        "        (:Person)-[:FOLLOWS]->(:Person)\n",
        "        (:Person)-[:REVIEWED]->(:Movie)\n",
        "    \"\"\"\n",
        "\n",
        "    # Evaluate the generated Cypher queries\n",
        "    results = []\n",
        "    total = len(EvalMovies)\n",
        "\n",
        "    for index, row in EvalMovies.iterrows():\n",
        "        NLQuestion = row['Natural_Language_Question']\n",
        "        expected_query = row['Cypher_Query']\n",
        "        metrics = evaluate_generated_query(NLQuestion, expected_query, schema)\n",
        "        results.append(metrics)\n",
        "    # Calculate average scores\n",
        "    avg_bleu = sum(result['bleu'] for result in results) / total\n",
        "    # avg_meteor = sum(result['meteor'] for result in results) / total\n",
        "    avg_rouge1 = sum(result['rouge1'] for result in results) / total\n",
        "    avg_rougeL = sum(result['rougeL'] for result in results) / total\n",
        "\n",
        "    print(f\"Average BLEU Score: {avg_bleu:.2f}\")\n",
        "    # print(f\"Average METEOR Score: {avg_meteor:.2f}\")\n",
        "    print(f\"Average ROUGE-1 Score: {avg_rouge1:.2f}\")\n",
        "    print(f\"Average ROUGE-L Score: {avg_rougeL:.2f}\")\n"
      ],
      "metadata": {
        "collapsed": true,
        "id": "qmnprNJOLn9w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Companies Dataset\n"
      ],
      "metadata": {
        "id": "3gmdZwVZeqz4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Set up the OpenAI API key\n",
        "openai.api_key = 'sk-proj-'\n",
        "\n",
        "COM_CYPHER_GENERATION_TEMPLATE = \"\"\"\n",
        "[INST]\n",
        "You are an expert Neo4j Developer translating user questions into Cypher to answer questions about Companies and provide information of the persons involved in.\n",
        "Convert the user's question based on the schema.\n",
        "\n",
        "Instructions:\n",
        "    1. Use only the provided relationship types and properties in the schema.\n",
        "    2. Do not use any other relationship types or properties that are not provided.\n",
        "    3. Even If no data is returned, Generate the Cypher.\n",
        "    4. Only respond to questions that require you to construct a Cypher statement.\n",
        "    5. Do not respond to any questions that might ask anything else than for you to construct a Cypher statement.\n",
        "    6. Do not include any explanations or apologies in your responses.\n",
        "    7. Do not include any text except the generated Cypher statement.\n",
        "    8. Generate the Cypher, even if there are exceptions and errors in the query.\n",
        "\n",
        "Schema: {schema}\n",
        "Question: {question}\n",
        "List all organizations headquartered in New York.\n",
        "[/INST]\n",
        "Query:\n",
        "MATCH (org:Organization)-[:IN_CITY]->(:City {{name: \"New York City\"}})\n",
        "RETURN org.name as ListOfOrganizations\n",
        "\"\"\"\n",
        "\n",
        "def generate_cypher(prompt, schema):\n",
        "    formatted_prompt = COM_CYPHER_GENERATION_TEMPLATE.format(schema=schema, question=prompt)\n",
        "    response = openai.ChatCompletion.create(\n",
        "        model=\"gpt-3.5-turbo\",\n",
        "        messages=[\n",
        "            {\"role\": \"user\", \"content\": formatted_prompt}\n",
        "        ]\n",
        "    )\n",
        "\n",
        "    # Extract the Cypher query from the response\n",
        "    cypher_query = response['choices'][0]['message']['content'].strip()\n",
        "    return cypher_query\n",
        "\n",
        "def run_cypher_query(query):\n",
        "    # Replace with your Neo4j connection details\n",
        "    uri = \"neo4j+s://demo.neo4jlabs.com\"\n",
        "    user = \"companies\"\n",
        "    password = \"companies\"\n",
        "\n",
        "    driver = GraphDatabase.driver(uri, auth=(user, password))\n",
        "\n",
        "    with driver.session() as session:\n",
        "        result = session.run(query)\n",
        "        return result.values()\n",
        "\n",
        "def evaluate_generated_query(question, expected_query, schema):\n",
        "    generated_query = generate_cypher(question, schema)\n",
        "    print(f\"Natural_Language_Question: {question}\")\n",
        "    print(f\"Generated Query: {generated_query}\")\n",
        "    print(f\"Expected Query: {expected_query}\")\n",
        "\n",
        "    # Tokenize the queries\n",
        "    generated_tokens = generated_query.split()\n",
        "    expected_tokens = expected_query.split()\n",
        "\n",
        "    Smooth = SmoothingFunction() # method0 .... method7 (0.14, 0.20, 0.30, 0.29,0.21, 0.21, err, 0.27 )\n",
        "    # BLEU score\n",
        "    bleu_score = sentence_bleu([expected_tokens], generated_tokens, smoothing_function=Smooth.method2 )\n",
        "\n",
        "    # ROUGE score\n",
        "    scorer = rouge_scorer.RougeScorer(['rouge1', 'rougeL'], use_stemmer=True)\n",
        "    rouge_scores = scorer.score(expected_query, generated_query)\n",
        "\n",
        "    return {\n",
        "        \"bleu\": bleu_score,\n",
        "        \"rouge1\": rouge_scores['rouge1'].fmeasure,\n",
        "        \"rougeL\": rouge_scores['rougeL'].fmeasure\n",
        "    }\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "\n",
        "    # Define the schema\n",
        "    schema = \"\"\"\n",
        "    Node properties are the following:\n",
        "    _Bloom_Scene_ {{ranges: STRING, gds: STRING, createdAt: INTEGER, lastModified: INTEGER, style: STRING, createdBy: STRING, visualisation: STRING, version: STRING, roles: LIST, numOfNodes: INTEGER, numOfRels: INTEGER, id: STRING, relationships: STRING, name: STRING, nodes: STRING}},\n",
        "    _Bloom_Perspective_ {{data: STRING, version: STRING, roles: LIST, name: STRING, id: STRING}},\n",
        "    Person {{name: STRING, id: STRING, summary: STRING}},\n",
        "    Organization {{name: STRING, nbrEmployees: INTEGER, isDissolved: BOOLEAN, id: STRING, motto: STRING, summary: STRING, isPublic: BOOLEAN, revenue: FLOAT}},\n",
        "    IndustryCategory {{name: STRING, id: STRING}},\n",
        "    City {{id: STRING, summary: STRING, name: STRING}},\n",
        "    Country {{name: STRING, id: STRING, summary: STRING}},\n",
        "    Article {{id: STRING, sentiment: FLOAT, author: STRING, siteName: STRING, summary: STRING, date: DATE_TIME, title: STRING}},\n",
        "    Chunk {{text: STRING, embedding: LIST, embedding_google: LIST}},\n",
        "    Fewshot {{Question: STRING, Cypher: STRING, id: INTEGER, embedding: LIST}}\n",
        "\n",
        "    Relationship properties are the following:\n",
        "\n",
        "    The relationships are the following:\n",
        "    (:_Bloom_Perspective_)-[:_Bloom_HAS_SCENE_]->(:_Bloom_Scene_),\n",
        "    (:Person)-[:HAS_PARENT]->(:Person),\n",
        "    (:Person)-[:HAS_CHILD]->(:Person),\n",
        "    (:Organization)-[:HAS_CEO]->(:Person),\n",
        "    (:Organization)-[:IN_CITY]->(:City),\n",
        "    (:Organization)-[:HAS_CATEGORY]->(:IndustryCategory),\n",
        "    (:Organization)-[:HAS_SUBSIDIARY]->(:Organization),\n",
        "    (:Organization)-[:HAS_SUPPLIER]->(:Organization),\n",
        "    (:Organization)-[:HAS_BOARD_MEMBER]->(:Person),\n",
        "    (:Organization)-[:HAS_INVESTOR]->(:Organization),\n",
        "    (:Organization)-[:HAS_INVESTOR]->(:Person),\n",
        "    (:Organization)-[:HAS_COMPETITOR]->(:Organization),\n",
        "    (:City)-[:IN_COUNTRY]->(:Country),\n",
        "    (:Article)-[:HAS_CHUNK]->(:Chunk),\n",
        "    (:Article)-[:MENTIONS]->(:Organization)\n",
        "    \"\"\"\n",
        "\n",
        "    # Evaluate the generated Cypher queries\n",
        "    results = []\n",
        "    total = len(EvalCompanies)\n",
        "\n",
        "    for index, row in EvalCompanies.iterrows():\n",
        "        ComNLQuestion = row['Natural_Language_Question']\n",
        "        Com_expected_query = row['Cypher_Query']\n",
        "        metrics = evaluate_generated_query(ComNLQuestion, Com_expected_query, schema)\n",
        "        results.append(metrics)\n",
        "\n",
        "    # Calculate average scores\n",
        "    avg_bleu = sum(result['bleu'] for result in results) / total\n",
        "    avg_rouge1 = sum(result['rouge1'] for result in results) / total\n",
        "    avg_rougeL = sum(result['rougeL'] for result in results) / total\n",
        "\n",
        "    print(f\"Average BLEU Score: {avg_bleu:.2f}\")\n",
        "    print(f\"Average ROUGE-1 Score: {avg_rouge1:.2f}\")\n",
        "    print(f\"Average ROUGE-L Score: {avg_rougeL:.2f}\")"
      ],
      "metadata": {
        "collapsed": true,
        "id": "NsYTR-8Eey6_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# On Netowrk Dataset"
      ],
      "metadata": {
        "id": "vMeYgMlbd4vU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Set up the OpenAI API key\n",
        "openai.api_key = 'sk-proj---'\n",
        "\n",
        "NET_CYPHER_GENERATION_TEMPLATE = \"\"\"\n",
        "[INST]\n",
        "You are an expert Neo4j Developer translating user questions into Cypher to answer questions about Network infrustracture components information.\n",
        "Convert the user's question based on the schema.\n",
        "\n",
        "Instructions:\n",
        "    1. Use only the provided relationship types and properties in the schema.\n",
        "    2. Do not use any other relationship types or properties that are not provided.\n",
        "    3. Even If no data is returned, Generate the Cypher.\n",
        "    4. Only respond to questions that require you to construct a Cypher statement.\n",
        "    5. Do not respond to any questions that might ask anything else than for you to construct a Cypher statement.\n",
        "    6. Do not include any explanations or apologies in your responses.\n",
        "    7. Do not include any text except the generated Cypher statement.\n",
        "    8. Generate the Cypher, even if there are exceptions and errors in the query.\n",
        "\n",
        "Schema: {schema}\n",
        "Question: {question}\n",
        "Retrieve all Routers connected to an interface\n",
        "[/INST]\n",
        "Query:\n",
        "MATCH (r:Router)-[:ROUTES]->(i:Interface)\n",
        "RETURN r.name\n",
        "\"\"\"\n",
        "\n",
        "def generate_cypher(prompt, schema):\n",
        "    formatted_prompt = NET_CYPHER_GENERATION_TEMPLATE.format(schema=schema, question=prompt)\n",
        "    response = openai.ChatCompletion.create(\n",
        "        model=\"gpt-3.5-turbo\",\n",
        "        messages=[\n",
        "            {\"role\": \"user\", \"content\": formatted_prompt}\n",
        "        ]\n",
        "    )\n",
        "\n",
        "    # Extract the Cypher query from the response\n",
        "    cypher_query = response['choices'][0]['message']['content'].strip()\n",
        "    return cypher_query\n",
        "\n",
        "def run_cypher_query(query):\n",
        "    # Replace with your Neo4j connection details\n",
        "    uri = \"neo4j+s://demo.neo4jlabs.com\"\n",
        "    user = \"network\"\n",
        "    password = \"network\"\n",
        "\n",
        "    driver = GraphDatabase.driver(uri, auth=(user, password))\n",
        "\n",
        "    with driver.session() as session:\n",
        "        result = session.run(query)\n",
        "        return result.values()\n",
        "\n",
        "def evaluate_generated_query(question, expected_query, schema):\n",
        "    generated_query = generate_cypher(question, schema)\n",
        "    print(f\"Natural_Language_Question: {question}\")\n",
        "    print(f\"Generated Query: {generated_query}\")\n",
        "    print(f\"Expected Query: {expected_query}\")\n",
        "\n",
        "    # Tokenize the queries\n",
        "    generated_tokens = generated_query.split()\n",
        "    expected_tokens = expected_query.split()\n",
        "\n",
        "    Smooth = SmoothingFunction() # method0 .... method7 (0.14, 0.20, 0.30, 0.29,0.21, 0.21, err, 0.27 )\n",
        "    # BLEU score\n",
        "    bleu_score = sentence_bleu([expected_tokens], generated_tokens, smoothing_function=Smooth.method2 )\n",
        "\n",
        "    # ROUGE score\n",
        "    scorer = rouge_scorer.RougeScorer(['rouge1', 'rougeL'], use_stemmer=True)\n",
        "    rouge_scores = scorer.score(expected_query, generated_query)\n",
        "\n",
        "    return {\n",
        "        \"bleu\": bleu_score,\n",
        "        \"rouge1\": rouge_scores['rouge1'].fmeasure,\n",
        "        \"rougeL\": rouge_scores['rougeL'].fmeasure\n",
        "    }\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "\n",
        "    # Define the schema as a string (this should match the actual schema of your Neo4j database)\n",
        "    schema = \"\"\"\n",
        "    Node properties are the following:\n",
        "      DataCenter {name: STRING, location: STRING},\n",
        "      Router {name: STRING, zone: INTEGER},\n",
        "      Egress {name: STRING}, Interface {ip: STRING},\n",
        "      Network {ip: STRING, size: INTEGER, zone: INTEGER},\n",
        "      Zone {ip: STRING, size: INTEGER, zone: INTEGER},\n",
        "      Rack {name: STRING, zone: INTEGER, rack: INTEGER},\n",
        "      Switch {ip: STRING, rack: INTEGER},\n",
        "      Type {id: INTEGER, type: STRING, ram: INTEGER, name: STRING, disk: INTEGER, cpu: INTEGER},\n",
        "      Machine {name: STRING}, Software {name: STRING, versions: LIST, ports: LIST, dependencies: LIST},\n",
        "      OS {name: STRING, startTime: INTEGER}, Service {name: STRING, startTime: INTEGER, pid: INTEGER},\n",
        "      Application {name: STRING, startTime: INTEGER, pid: INTEGER}, Version {name: STRING},\n",
        "      Process {name: STRING, startTime: INTEGER, pid: INTEGER}, Port {port: INTEGER}\n",
        "    Relationship properties are the following:\n",
        "\n",
        "    The relationships are the following:\n",
        "      (:DataCenter)-[:CONTAINS]->(:Rack), (:DataCenter)-[:CONTAINS]->(:Router),\n",
        "      (:DataCenter)-[:CONTAINS]->(:Egress), (:Router)-[:ROUTES]->(:Interface), (:Egress)-[:ROUTES]->(:Interface),\n",
        "      (:Interface)-[:EXPOSES]->(:Port), (:Interface)-[:CONNECTS]->(:Interface), (:Network)-[:ROUTES]->(:Interface),\n",
        "      (:Zone)-[:ROUTES]->(:Interface), (:Rack)-[:HOLDS]->(:Machine), (:Rack)-[:HOLDS]->(:Switch), (:Switch)-[:ROUTES]->(:Interface),\n",
        "      (:Machine)-[:RUNS]->(:Application), (:Machine)-[:RUNS]->(:Process), (:Machine)-[:RUNS]->(:OS), (:Machine)-[:RUNS]->(:Service),\n",
        "      (:Machine)-[:ROUTES]->(:Interface), (:Machine)-[:TYPE]->(:Type), (:Software)-[:VERSION]->(:Version),\n",
        "      (:Software)-[:DEPENDS_ON]->(:Version), (:Software)-[:DEPENDS_ON]->(:Software), (:Software)-[:DEPENDS_ON]->(:Application),\n",
        "      (:Software)-[:DEPENDS_ON]->(:Service), (:OS)-[:INSTANCE]->(:Version), (:Service)-[:INSTANCE]->(:Software),\n",
        "      (:Service)-[:INSTANCE]->(:Version), (:Service)-[:INSTANCE]->(:Application), (:Service)-[:INSTANCE]->(:Service),\n",
        "      (:Service)-[:LISTENS]->(:Port), (:Application)-[:INSTANCE]->(:Software), (:Application)-[:INSTANCE]->(:Application),\n",
        "      (:Application)-[:LISTENS]->(:Port), (:Application)-[:DEPENDS_ON]->(:Service), (:Application)-[:DEPENDS_ON]->(:Process),\n",
        "      (:Version)-[:PREVIOUS]->(:Version), (:Process)-[:LISTENS]->(:Port), (:Process)-[:INSTANCE]->(:Software),\n",
        "      (:Process)-[:INSTANCE]->(:Application), (:Process)-[:INSTANCE]->(:Version), (:Process)-[:INSTANCE]->(:Service),\n",
        "      (:Process)-[:DEPENDS_ON]->(:Service), (:Process)-[:DEPENDS_ON]->(:Process)\n",
        "    \"\"\"\n",
        "\n",
        "    # Evaluate the generated Cypher queries\n",
        "    results = []\n",
        "    total = len(EvalNetwork)\n",
        "\n",
        "    for index, row in EvalNetwork.iterrows():\n",
        "        NetNLQuestion = row['Natural_Language_Question']\n",
        "        Net_expected_query = row['Cypher_Query']\n",
        "        metrics = evaluate_generated_query(NetNLQuestion, Net_expected_query, schema)\n",
        "        results.append(metrics)\n",
        "\n",
        "    # Calculate average scores\n",
        "    avg_bleu = sum(result['bleu'] for result in results) / total\n",
        "    avg_rouge1 = sum(result['rouge1'] for result in results) / total\n",
        "    avg_rougeL = sum(result['rougeL'] for result in results) / total\n",
        "\n",
        "    print(f\"Average BLEU Score: {avg_bleu:.2f}\")\n",
        "    print(f\"Average ROUGE-1 Score: {avg_rouge1:.2f}\")\n",
        "    print(f\"Average ROUGE-L Score: {avg_rougeL:.2f}\")"
      ],
      "metadata": {
        "collapsed": true,
        "id": "ArM3owwRd9yy"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}